{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inputs and obvious corrections\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data and working with arrays\n",
    "import nrrd\n",
    "import zarr\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# data paths\n",
    "p = ''\n",
    "fix_path = p + ''\n",
    "mov_path = p + ''\n",
    "\n",
    "# load fix data, reflect to match functional data\n",
    "fix_zarr = zarr.open(store=zarr.N5Store(fix_path), mode='r')\n",
    "fix_meta = fix_zarr['/c2/s3'].attrs.asdict()\n",
    "fix = fix_zarr['/c2/s3'][...].transpose(1,2,0)[:, ::-1, :]\n",
    "\n",
    "# load mov data, reflect to match functional data\n",
    "mov_zarr = zarr.open(store=zarr.N5Store(mov_path), mode='r')\n",
    "mov_meta = mov_zarr['/c3/s3'].attrs.asdict()\n",
    "mov = mov_zarr['/c3/s3'][...].transpose(1,2,0)[:, ::-1, :]\n",
    "\n",
    "# spacings\n",
    "fix_spacing = np.array(fix_meta['pixelResolution']) * fix_meta['downsamplingFactors']\n",
    "mov_spacing = np.array(mov_meta['pixelResolution']) * mov_meta['downsamplingFactors']\n",
    "\n",
    "# adjust mov_spacing by expansion factor to get pre-expansion size\n",
    "exp_factor = 2\n",
    "fix_spacing = fix_spacing / exp_factor\n",
    "mov_spacing = mov_spacing / exp_factor\n",
    "\n",
    "# write results\n",
    "nrrd.write('./fix.nrrd', fix, compression_level=2)\n",
    "nrrd.write('./mov.nrrd', mov, compression_level=2)\n",
    "\n",
    "# check spacings\n",
    "print(fix.shape, mov.shape)\n",
    "print(fix_spacing, mov_spacing)\n",
    "\n",
    "# # load precomputed data\n",
    "# fix, _ = nrrd.read('./fix.nrrd')\n",
    "# mov, _ = nrrd.read('./mov.nrrd')\n",
    "# fix_spacing = np.array([0.928184, 0.928184, 0.84    ])\n",
    "# mov_spacing = np.array([0.92768,  0.92768,  0.846698])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Foreground detection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tools for coarse whole brain segmentation\n",
    "from CircuitSeeker import level_set\n",
    "from scipy.ndimage import zoom, binary_closing, binary_dilation\n",
    "\n",
    "# get small mask\n",
    "fix_skip = fix[::4, ::4, ::4]\n",
    "skip_spacing = fix_spacing * [4, 4, 4]\n",
    "fix_mask_small = level_set.brain_detection(\n",
    "    fix_skip, skip_spacing,\n",
    "    mask_smoothing=2,\n",
    "    iterations=[80,40,10],\n",
    "    smooth_sigmas=[12,6,3],\n",
    "    lambda2=64.0,\n",
    ")\n",
    "\n",
    "# enlarge and smooth mask\n",
    "fix_mask = zoom(fix_mask_small, np.array(fix.shape) / fix_skip.shape, order=0)\n",
    "fix_mask = binary_closing(fix_mask, np.ones((5,5,5))).astype(np.uint8)\n",
    "fix_mask = binary_dilation(fix_mask, np.ones((5,5,5))).astype(np.uint8)\n",
    "\n",
    "# write result\n",
    "nrrd.write('./fix_mask.nrrd', fix_mask)\n",
    "\n",
    "# # load precomputed mask\n",
    "# fix_mask, _ = nrrd.read('./fix_mask.nrrd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tools for coarse whole brain segmentation\n",
    "from CircuitSeeker import level_set\n",
    "from scipy.ndimage import zoom, binary_closing, binary_dilation\n",
    "\n",
    "# get small mask\n",
    "mov_skip = mov[::4, ::4, ::4]\n",
    "skip_spacing = mov_spacing * [4, 4, 4]\n",
    "mov_mask_small = level_set.brain_detection(\n",
    "    mov_skip, skip_spacing,\n",
    "    mask_smoothing=2,\n",
    "    iterations=[80,40,10],\n",
    "    smooth_sigmas=[12,6,3],\n",
    "    lambda2=64.0,\n",
    ")\n",
    "\n",
    "# enlarge and smooth mask\n",
    "mov_mask = zoom(mov_mask_small, np.array(mov.shape) / mov_skip.shape, order=0)\n",
    "mov_mask = binary_closing(mov_mask, np.ones((5,5,5))).astype(np.uint8)\n",
    "mov_mask = binary_dilation(mov_mask, np.ones((5,5,5))).astype(np.uint8)\n",
    "\n",
    "# save output\n",
    "nrrd.write('./mov_mask.nrrd', mov_mask)\n",
    "\n",
    "# # load precomputed mask\n",
    "# mov_mask, _ = nrrd.read('./mov_mask.nrrd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Moments alignment\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CircuitSeeker.axisalign import principal_axes, align_modes\n",
    "from CircuitSeeker.transform import apply_transform\n",
    "\n",
    "# get modes and align\n",
    "fix_mean, fix_evals, fix_evecs = principal_axes(fix_mask, fix_spacing)\n",
    "mov_mean, mov_evals, mov_evecs = principal_axes(mov_mask, mov_spacing)\n",
    "modes = align_modes(fix_mean, fix_evecs, mov_mean, mov_evecs)\n",
    "\n",
    "# apply mode transform\n",
    "modes_aligned = apply_transform(\n",
    "    fix, mov,\n",
    "    fix_spacing, mov_spacing,\n",
    "    transform_list=[modes,],\n",
    ")\n",
    "\n",
    "# write results\n",
    "np.savetxt('modes.mat', modes)\n",
    "nrrd.write('./modes.nrrd', modes_aligned, compression_level=2)\n",
    "\n",
    "# # load precomputed mode results\n",
    "# modes = np.loadtxt('./modes.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Whole Image Alignment\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alignment functions\n",
    "from CircuitSeeker.align import alignment_pipeline\n",
    "from CircuitSeeker.align import deformable_align\n",
    "from CircuitSeeker.transform import apply_transform\n",
    "\n",
    "\n",
    "affine, deform = alignment_pipeline(\n",
    "    fix, mov, fix_spacing, mov_spacing,\n",
    "    steps=['rigid', 'affine', 'deform'],\n",
    "    initial_transform=modes,\n",
    "    alignment_spacing=2.0,\n",
    "    shrink_factors=[2,],\n",
    "    smooth_sigmas=[2.,],\n",
    "    iterations=400,\n",
    "    deform_kwargs={\n",
    "        'control_point_spacing':100.0,\n",
    "        'control_point_levels':[1,],\n",
    "    }\n",
    ")\n",
    "\n",
    "# we don't need bspline params, just field\n",
    "deform = deform[1]\n",
    "\n",
    "# apply affine only\n",
    "affine_aligned = apply_transform(\n",
    "    fix, mov,\n",
    "    fix_spacing, mov_spacing,\n",
    "    transform_list=[affine,],\n",
    ")\n",
    "\n",
    "# apply affine and deform\n",
    "deform_aligned = apply_transform(\n",
    "    fix, mov,\n",
    "    fix_spacing, mov_spacing,\n",
    "    transform_list=[affine, deform],\n",
    ")\n",
    "\n",
    "# write results\n",
    "np.savetxt('affine.mat', affine)\n",
    "nrrd.write('./deform.nrrd', deform, compression_level=2)\n",
    "nrrd.write('./affine.nrrd', affine_aligned, compression_level=2)\n",
    "nrrd.write('./deformed.nrrd', deform_aligned, compression_level=2)\n",
    "\n",
    "# # load precomputed results\n",
    "# affine = np.loadtxt('./affine.mat')\n",
    "# deform, _ = nrrd.read('./deform.nrrd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiggle\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for overlapping affine alignments\n",
    "from CircuitSeeker.align import nested_distributed_piecewise_alignment_pipeline\n",
    "\n",
    "# define blocks\n",
    "block_schedule = [ [tuple(np.round(np.array(fix.shape) / 32).astype(int))], ]\n",
    "\n",
    "# define parameters\n",
    "parameter_schedule = [\n",
    "    {'random_kwargs':{'max_translation':5.,\n",
    "                      'max_rotation':5. * np.pi/180.,\n",
    "                      'max_scale':1.05,\n",
    "                      'max_shear':.05,\n",
    "                      'random_iterations':2500,\n",
    "                      'affine_align_best':10,\n",
    "                      'iterations':24,},\n",
    "     'affine_kwargs':{},\n",
    "     'deform_kwargs':{'control_point_spacing':29.0,\n",
    "                      'control_point_levels':[1,],\n",
    "                      'iterations':100,\n",
    "                      'metric':'MI',},\n",
    "    },\n",
    "]\n",
    "\n",
    "# run twist\n",
    "wiggle = nested_distributed_piecewise_alignment_pipeline(\n",
    "    fix,\n",
    "    mov,\n",
    "    fix_spacing,\n",
    "    mov_spacing,\n",
    "    block_schedule,\n",
    "    parameter_schedule=parameter_schedule,\n",
    "    initial_transform_list=[affine, deform,],\n",
    "    fix_mask=fix_mask,\n",
    "    mov_mask=mov_mask,\n",
    "    steps=['random', 'affine', 'deform'],\n",
    "    bins=256,\n",
    "    shrink_factors=[1,],\n",
    "    smooth_sigmas=[1.,],\n",
    "    iterations=400,\n",
    "    learning_rate=0.1,\n",
    "    max_step=0.1,\n",
    "    estimate_learning_rate='never',\n",
    "    callback=lambda irm: None,\n",
    "    intermediates_path='./',\n",
    "    cluster_kwargs={\n",
    "        'ncpus':6,\n",
    "        'threads':6,\n",
    "        'min_workers':25,\n",
    "        'max_workers':25,\n",
    "    },\n",
    ")\n",
    "\n",
    "# apply twist\n",
    "wiggled = apply_transform(\n",
    "    fix, mov,\n",
    "    fix_spacing, mov_spacing,\n",
    "    transform_list=[affine, deform, wiggle,],\n",
    ")\n",
    "\n",
    "# write results\n",
    "nrrd.write('./wiggle.nrrd', wiggle, compression_level=2)\n",
    "nrrd.write('./wiggled.nrrd', wiggled, compression_level=2)\n",
    "\n",
    "# # load precomputed results\n",
    "# wiggle, _ = nrrd.read('./wiggle.nrrd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invert all transforms\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CircuitSeeker.transform import invert_displacement_vector_field\n",
    "from CircuitSeeker.transform import apply_transform\n",
    "\n",
    "# invert affine\n",
    "affine_inv = np.linalg.inv(affine)\n",
    "np.savetxt('./affine_inverse.mat', affine_inv)\n",
    "\n",
    "# invert deform\n",
    "deform_inv = invert_displacement_vector_field(deform, fix_spacing)\n",
    "nrrd.write('./deform_inverse.nrrd', deform_inv, compression_level=2)\n",
    "\n",
    "# invert wiggle\n",
    "wiggle_inv = invert_displacement_vector_field(wiggle, fix_spacing)\n",
    "nrrd.write('./wiggle_inverse.nrrd', wiggle_inv, compression_level=2)\n",
    "\n",
    "# test via image resampling\n",
    "fix_to_mov = apply_transform(\n",
    "    mov, fix, mov_spacing, fix_spacing,\n",
    "    transform_list=[wiggle_inv, deform_inv, affine_inv],\n",
    "    transform_spacing=fix_spacing,\n",
    ")\n",
    "nrrd.write('./fix_warped_to_mov.nrrd', fix_to_mov, compression_level=2)\n",
    "\n",
    "# # load precomputed results\n",
    "# affine_inv = np.loadtxt('./affine_inverse.mat')\n",
    "# deform_inv, _ = nrrd.read('./deform_inverse.nrrd')\n",
    "# wiggle_inv, _ = nrrd.read('./wiggle_inverse.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CircuitSeeker",
   "language": "python",
   "name": "circuitseeker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
